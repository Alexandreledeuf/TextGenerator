{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd2f9e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose 1 topic :0. depression, 1. evil, 2. funny, 3. god, 4. love, 5. moon, 6. mother, 7. romance, 8. war, 9. wedding \n",
      "1\n",
      "Write the begining of a sentence. (3 words)The evil will\n",
      "The evil will he was conscripted as a sayest i what we say not a woman made you cry as if you support take my heart fate that is long and keep back is at them god is detail but refs decision alive by the green bean before my eyes thy handy when you attacked me whenever the blood who heard it out of his victim offend the wrath of god… lurking paster dawn all the good who seemed to begin gone on holiday god moves in mysterious ways that can be be the bad apples inside my eyes – is hunger invades tiny bellies way there is the root of all this angel has cover that sows he became a certain pain mind fate you the needs or those i misperceive we are born with a priest men you knew her children still could they say this need this need you a gloom of cheer who created us who loves us and who providentially manages the world the twilight fails hate mist not as flaws in ignition long we all no more life wanted to give and torture and iraq and thrashed…while evil day evil will grow as long disordered involved else around the good wins wars of abuse i feel this land peace nature life are would a woman wanted all war worlds woman here he was reported in indonesia and iraq and afghanistan every good peace but she said theres all pain is worlds true he game is laughter peace ive always all sure laughter peace blood but envious love fooled fools us the love comes you quite wanted all all is flaws in great that is all god squarely to smoke ganja reason was all flaws peace but peace is suffocating in a butterfly good is laughter of bed\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import exists\n",
    "import csv\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from keras.utils import np_utils\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Dropout, Bidirectional, GlobalMaxPooling1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#obtenir les lignes de chaque poèmes\n",
    "def ObtainTexts(theme):\n",
    "    LigneTexte = []\n",
    "    repo = \"PoemTopics/\"+ str(theme) + \"/\"\n",
    "    for filename in os.listdir(repo):\n",
    "        dir = str(repo)+str(filename)\n",
    "        file = open(dir, encoding=\"utf8\")\n",
    "        while(True):\n",
    "            texte = []\n",
    "            line = file.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            else:\n",
    "                LigneTexte.append(line)\n",
    "    return LigneTexte\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r',', '', text)\n",
    "    text = re.sub(r'\\'', '',  text)\n",
    "    text = re.sub(r'\\\"', '', text)\n",
    "    text = re.sub(r'\\(', '', text)\n",
    "    text = re.sub(r'\\)', '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'“', '', text)\n",
    "    text = re.sub(r'”', '', text)\n",
    "    text = re.sub(r'’', '', text)\n",
    "    text = re.sub(r'\\.', '', text)\n",
    "    text = re.sub(r';', '', text)\n",
    "    text = re.sub(r':', '', text)\n",
    "    text = re.sub(r'\\-', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def dataCleaning(LigneTexte):\n",
    "    #enlever les \\n\n",
    "    for i in range(len(LigneTexte)):\n",
    "        LigneTexte[i] = LigneTexte[i].replace('\\n', '')\n",
    "        LigneTexte[i] = LigneTexte[i].lower()\n",
    "        LigneTexte[i] = clean_text(LigneTexte[i])\n",
    "    return LigneTexte\n",
    "\n",
    "def tokenize(LigneTexte):\n",
    "   # Instantiating the Tokenizer\n",
    "    max_vocab = 1000000\n",
    "    tokenizer = Tokenizer(num_words=max_vocab)\n",
    "    tokenizer.fit_on_texts(LigneTexte)   \n",
    "\n",
    "    # Getting the total number of words of the data.\n",
    "    word2idx = tokenizer.word_index\n",
    "    vocab_size = len(word2idx) + 1 \n",
    "    return vocab_size, tokenizer\n",
    "\n",
    "# We will turn the sentences to sequences line by line and create n_gram sequences\n",
    "def sentToSeq(LigneTexte,tokenizer):\n",
    "    input_seq = []\n",
    "\n",
    "    for line in LigneTexte:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_seq = token_list[:i+1]\n",
    "            input_seq.append(n_gram_seq)\n",
    "    return input_seq\n",
    "\n",
    "# Getting the maximum length of sequence for padding purpose\n",
    "def maxLenSequence(input_seq):\n",
    "    return max(len(x) for x in input_seq)\n",
    "\n",
    "# Padding the sequences and converting them to array\n",
    "def padAndArray(input_seq,max_seq_length):\n",
    "    return np.array(pad_sequences(input_seq, maxlen=max_seq_length, padding='pre'))\n",
    "\n",
    "# Taking xs and labels to train the model.\n",
    "def XAndLabel(input_seq):\n",
    "    xs = input_seq[:, :-1]        # xs contains every word in sentence except the last one because we are using this value to predict the y value\n",
    "    labels = input_seq[:, -1]     # labels contains only the last word of the sentence which will help in hot encoding the y value in next step\n",
    "    return xs,labels\n",
    "\n",
    "# one-hot encoding the labels according to the vocab size\n",
    "\n",
    "# The matrix is square matrix of the size of vocab_size. Each row will denote a label and it will have \n",
    "# a single +ve value(i.e 1) for that label and other values will be zero. \n",
    "def categorical(labels,vocab_size):\n",
    "    return to_categorical(labels, num_classes=vocab_size)\n",
    "\n",
    "\n",
    "def textGeneratorModel(vocab_size,max_seq_length,xs,ys,theme):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, input_length=max_seq_length-1))\n",
    "    model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(vocab_size/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    #model.compile(optimizer=Adam(lr=0.001),loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    r = model.fit(xs,ys,epochs=125)\n",
    "    \n",
    "    repo = \"models/model_\"+str(theme)+\".h5\"\n",
    "    model.save(repo)\n",
    "    return r\n",
    "\n",
    "def DisplayAccuracy(r):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(r.history['accuracy'])\n",
    "    \n",
    "def predict_words(seed, no_words,model,tokenizer,maxLenInputSeq,theme):\n",
    "    for i in range(no_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=maxLenInputSeq-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=1)\n",
    "\n",
    "        new_word = ''\n",
    "\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if predicted == index:\n",
    "                new_word = word\n",
    "                break\n",
    "        seed += \" \" + new_word\n",
    "    print(seed)\n",
    "    filename = \"./outputs/\"+str(theme) + \".txt\"\n",
    "    with open(filename, 'w') as txtfile:\n",
    "        txtfile.write(seed) \n",
    "    \n",
    "    \n",
    "def Menu():\n",
    "    choice = ['depression','evil','funny','god','love','moon','mother','romance','war','wedding']\n",
    "    position = -1\n",
    "    while (position < 0 or position > 9):\n",
    "        try: \n",
    "            position = int(input(\"Choose 1 topic :0. depression, 1. evil, 2. funny, 3. god, 4. love, 5. moon, 6. mother, 7. romance, 8. war, 9. wedding \\n\"))\n",
    "        except: \n",
    "            print(\"Choose a number\")\n",
    "    return choice[position]\n",
    "        \n",
    "def main():\n",
    "    theme = Menu()\n",
    "    LigneTexte = ObtainTexts(theme)\n",
    "    LigneTexte = dataCleaning(LigneTexte)\n",
    "    vocab_size,tokenizer = tokenize(LigneTexte)\n",
    "    input_seq = sentToSeq(LigneTexte,tokenizer)\n",
    "    maxLenInputSeq = maxLenSequence(input_seq)\n",
    "    input_seq  = padAndArray(input_seq,maxLenInputSeq)\n",
    "    xs,labels = XAndLabel(input_seq)\n",
    "    ys = categorical(labels,vocab_size)\n",
    "    \n",
    "    repo = \"models/model_\"+str(theme)+\".h5\"\n",
    "    if not(exists(repo)):\n",
    "        r = textGeneratorModel(vocab_size,maxLenInputSeq,xs,ys,theme)\n",
    "        DisplayAccuracy(r)\n",
    "    \n",
    "    \n",
    "    model=load_model(repo) \n",
    "    seed_text = input('Write the begining of a sentence. (3 words)') #Début de la phrase, qui peut être changé mais seulement en Anglais\n",
    "    next_words = 300 #Nombre de mots que l'on veut générer\n",
    "    predict_words(seed_text, next_words,model,tokenizer,maxLenInputSeq,theme)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d61df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
