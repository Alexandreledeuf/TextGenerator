{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd2f9e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will die for dusk for was their accomplishment still above me to the bars to me with me close in the mothers in the war of their road to he love but common hang by scores like mites sir pike and soot mans buried close with his sack on death man wind wind fate be peaceful war soul of hate parts buried close bloody war of war fate time war fury strong war wind fate brown earth of soul to war heart at death war wind church strong war wind flies eer heart things home hate wind earth death war of anchor fate earth of soul to storm of soul and heart wind destined fury of mortal load even useful like brittle bed war knows wind day wind fury bells war earth and home on hate parts war wind wind wind wind heart wind toward his field on length hate fury fury fury fury dear cause things war lads church with spilled war fury hate fury hate earth and home from home parts butt in them death war wind church up gently in death wind wind cry upon this time her youth love ever say it already unknown useless appearance lies heart of his war fate can fully he deny my filthy and heart are war heart heart is been received himself leaves deny my campaigns man upon a war of friends a field of his field where his voyage photos in hate fury close war up of the road of home on others naught is mighty breath above jon winter rose stormy to the hungry earth to a war of war longer heart heart church of englands can slide it comes last battle patrician war on englands life hate as all to parachute a stout fellow equipped for the hungry i\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from keras.utils import np_utils\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Dropout, Bidirectional, GlobalMaxPooling1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#obtenir les lignes de chaque poèmes\n",
    "def ObtainTexts():\n",
    "    LigneTexte = []\n",
    "    for filename in os.listdir(\"war/\"):\n",
    "        dir = \"war/\"+str(filename)\n",
    "        file = open(dir, encoding=\"utf8\")\n",
    "        while(True):\n",
    "            texte = []\n",
    "            line = file.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            else:\n",
    "                LigneTexte.append(line)\n",
    "    return LigneTexte\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r',', '', text)\n",
    "    text = re.sub(r'\\'', '',  text)\n",
    "    text = re.sub(r'\\\"', '', text)\n",
    "    text = re.sub(r'\\(', '', text)\n",
    "    text = re.sub(r'\\)', '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'“', '', text)\n",
    "    text = re.sub(r'”', '', text)\n",
    "    text = re.sub(r'’', '', text)\n",
    "    text = re.sub(r'\\.', '', text)\n",
    "    text = re.sub(r';', '', text)\n",
    "    text = re.sub(r':', '', text)\n",
    "    text = re.sub(r'\\-', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def dataCleaning(LigneTexte):\n",
    "    #enlever les \\n\n",
    "    for i in range(len(LigneTexte)):\n",
    "        LigneTexte[i] = LigneTexte[i].replace('\\n', '')\n",
    "        LigneTexte[i] = LigneTexte[i].lower()\n",
    "        LigneTexte[i] = clean_text(LigneTexte[i])\n",
    "    return LigneTexte\n",
    "\n",
    "def tokenize(LigneTexte):\n",
    "   # Instantiating the Tokenizer\n",
    "    max_vocab = 1000000\n",
    "    tokenizer = Tokenizer(num_words=max_vocab)\n",
    "    tokenizer.fit_on_texts(LigneTexte)   \n",
    "\n",
    "    # Getting the total number of words of the data.\n",
    "    word2idx = tokenizer.word_index\n",
    "    vocab_size = len(word2idx) + 1 \n",
    "    return vocab_size, tokenizer\n",
    "\n",
    "# We will turn the sentences to sequences line by line and create n_gram sequences\n",
    "def sentToSeq(LigneTexte,tokenizer):\n",
    "    input_seq = []\n",
    "\n",
    "    for line in LigneTexte:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_seq = token_list[:i+1]\n",
    "            input_seq.append(n_gram_seq)\n",
    "    return input_seq\n",
    "\n",
    "# Getting the maximum length of sequence for padding purpose\n",
    "def maxLenSequence(input_seq):\n",
    "    return max(len(x) for x in input_seq)\n",
    "\n",
    "# Padding the sequences and converting them to array\n",
    "def padAndArray(input_seq,max_seq_length):\n",
    "    return np.array(pad_sequences(input_seq, maxlen=max_seq_length, padding='pre'))\n",
    "\n",
    "# Taking xs and labels to train the model.\n",
    "def XAndLabel(input_seq):\n",
    "    xs = input_seq[:, :-1]        # xs contains every word in sentence except the last one because we are using this value to predict the y value\n",
    "    labels = input_seq[:, -1]     # labels contains only the last word of the sentence which will help in hot encoding the y value in next step\n",
    "    return xs,labels\n",
    "\n",
    "# one-hot encoding the labels according to the vocab size\n",
    "\n",
    "# The matrix is square matrix of the size of vocab_size. Each row will denote a label and it will have \n",
    "# a single +ve value(i.e 1) for that label and other values will be zero. \n",
    "def categorical(labels,vocab_size):\n",
    "    return to_categorical(labels, num_classes=vocab_size)\n",
    "\n",
    "\n",
    "def textGeneratorModel(vocab_size,max_seq_length,xs,ys):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, input_length=max_seq_length-1))\n",
    "    model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(vocab_size/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \"\"\"\n",
    "    model.add(Embedding(vocab_size, 124, input_length=max_seq_length-1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(520, return_sequences=True))\n",
    "    model.add(Bidirectional(LSTM(340, return_sequences=True)))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=0.001),loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    r = model.fit(xs,ys,epochs=125)\n",
    "    model.save('modelWar.h5')\n",
    "    return r\n",
    "\n",
    "def DisplayAccuracy(r):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(r.history['accuracy'])\n",
    "    \n",
    "def predict_words(seed, no_words,model,tokenizer,maxLenInputSeq):\n",
    "    for i in range(no_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=maxLenInputSeq-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=1)\n",
    "\n",
    "        new_word = ''\n",
    "\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if predicted == index:\n",
    "                new_word = word\n",
    "                break\n",
    "        seed += \" \" + new_word\n",
    "    print(seed)\n",
    "    \n",
    "def main():\n",
    "    LigneTexte = ObtainTexts()\n",
    "    LigneTexte = dataCleaning(LigneTexte)\n",
    "    vocab_size,tokenizer = tokenize(LigneTexte)\n",
    "    input_seq = sentToSeq(LigneTexte,tokenizer)\n",
    "    maxLenInputSeq = maxLenSequence(input_seq)\n",
    "    input_seq  = padAndArray(input_seq,maxLenInputSeq)\n",
    "    xs,labels = XAndLabel(input_seq)\n",
    "    ys = categorical(labels,vocab_size)\n",
    "    #r = textGeneratorModel(vocab_size,maxLenInputSeq,xs,ys)\n",
    "    #DisplayAccuracy(r)\n",
    "\n",
    "    \n",
    "    model=load_model('modelWar.h5') \n",
    "    seed_text = 'You will die' #Début de la phrase, qui peut être changé mais seulement en Anglais\n",
    "    next_words = 300 #Nombre de mots que l'on veut générer\n",
    "    predict_words(seed_text, next_words,model,tokenizer,maxLenInputSeq)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d61df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
