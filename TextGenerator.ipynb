{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd2f9e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose 1 topic :0. depression, 1. evil, 2. funny, 3. god, 4. love, 5. moon, 6. mother, 7. romance, 8. war, 9. wedding \n",
      "1\n",
      "Write the begining of a sentence. (3 words)does the evil\n",
      "does the evil in your mate hell not many ripped and ragged rugs 3 years hunger goes you grow as long as the law of matches go off in your hand she in every faith is instead i see you make breakups of turning of a sudden of your wife by parents along the next day i will eat late for turning around you is this decaying evil soul the streets trying to begin drowned the cornland off never a woman made you pay at america need this phenomenon the divil wid a stablefork bedivillin their tails my memory of a box – preferably on a bed thinking if they could sing to aim i try her knuckles rubbishing each other and because old final words born but the towers side made to work that water is one must walk alone of if god can never throw in the field and street around the countries on strife your good man is his cries hate is she heard course… out the divil wouldnt shine an repair creature trying to charge me with sun darkness normal life of torment reason evil want that death is many innocent lives my chest mother beaten most sake wanted in quiet bad such loathed man knows that every good peace is instead i see yourself you are not worlds woman wanted close thin worlds pain worlds pain she all wanted to pain and smashed pushed and thrashed…while the last seeds of man intention fails called that moment love peace is fate quiet facethe altars one all apartments more than man wanted close fool wrong your good guys john wayne merriment satan she gave so prints love fear i was trapped flying mistakes twould hear a butterfly instincts lurking blood but good archangel old caves so beauty back only is\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import exists\n",
    "import csv\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from keras.utils import np_utils\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Dropout, Bidirectional, GlobalMaxPooling1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#obtenir les lignes de chaque poèmes\n",
    "def ObtainTexts(theme):\n",
    "    TextLine = []\n",
    "    repo = \"PoemTopics/\"+ str(theme) + \"/\"\n",
    "    for filename in os.listdir(repo):\n",
    "        dir = str(repo)+str(filename)\n",
    "        file = open(dir, encoding=\"utf8\")\n",
    "        while(True):\n",
    "            line = file.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            else:\n",
    "                TextLine.append(line)\n",
    "    return TextLine\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r',', '', text)\n",
    "    text = re.sub(r'\\'', '',  text)\n",
    "    text = re.sub(r'\\\"', '', text)\n",
    "    text = re.sub(r'\\(', '', text)\n",
    "    text = re.sub(r'\\)', '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'“', '', text)\n",
    "    text = re.sub(r'”', '', text)\n",
    "    text = re.sub(r'’', '', text)\n",
    "    text = re.sub(r'\\.', '', text)\n",
    "    text = re.sub(r';', '', text)\n",
    "    text = re.sub(r':', '', text)\n",
    "    text = re.sub(r'\\-', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def dataCleaning(TextLine):\n",
    "    #enlever les \\n\n",
    "    for i in range(len(TextLine)):\n",
    "        TextLine[i] = TextLine[i].replace('\\n', '')\n",
    "        TextLine[i] = TextLine[i].lower()\n",
    "        TextLine[i] = clean_text(TextLine[i])\n",
    "    return TextLine\n",
    "\n",
    "def tokenize(TextLine):\n",
    "   # Instantiating the Tokenizer\n",
    "    max_vocab = 1000000\n",
    "    tokenizer = Tokenizer(num_words=max_vocab)\n",
    "    tokenizer.fit_on_texts(TextLine)   \n",
    "\n",
    "    # Getting the total number of words of the data.\n",
    "    word2idx = tokenizer.word_index\n",
    "    vocab_size = len(word2idx) + 1 \n",
    "    return vocab_size, tokenizer\n",
    "\n",
    "# We will turn the sentences to sequences line by line and create n_gram sequences [3,67,2,...]\n",
    "def sentToSeq(TextLine,tokenizer):\n",
    "    input_seq = []\n",
    "\n",
    "    for line in TextLine:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_seq = token_list[:i+1]\n",
    "            input_seq.append(n_gram_seq)\n",
    "    return input_seq\n",
    "\n",
    "# Getting the maximum length of sequence for padding purpose\n",
    "def maxLenSequence(input_seq):\n",
    "    return max(len(x) for x in input_seq)\n",
    "\n",
    "# Padding the sequences and converting them to array\n",
    "def padAndArray(input_seq,max_seq_length):\n",
    "    return np.array(pad_sequences(input_seq, maxlen=max_seq_length, padding='pre'))\n",
    "\n",
    "# Taking xs and labels to train the model. [0,0,0,...,x] x is a word that has been categorise\n",
    "def XAndLabel(input_seq):\n",
    "    xs = input_seq[:, :-1]        # xs contains every word in sentence except the last one because we are using this value to predict the y value\n",
    "    labels = input_seq[:, -1]     # labels contains only the last word of the sentence which will help in hot encoding the y value in next step\n",
    "    return xs,labels\n",
    "\n",
    "# one-hot encoding the labels according to the vocab size\n",
    "\n",
    "# The matrix is square matrix of the size of vocab_size. Each row will denote a label and it will have \n",
    "# a single +ve value(i.e 1) for that label and other values will be zero. \n",
    "def categorical(labels,vocab_size):\n",
    "    return to_categorical(labels, num_classes=vocab_size)\n",
    "\n",
    "\n",
    "def textGeneratorModel(vocab_size,max_seq_length,xs,ys,theme):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, input_length=max_seq_length-1))\n",
    "    model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(vocab_size/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    r = model.fit(xs,ys,epochs=125)\n",
    "    \n",
    "    repo = \"models/model_\"+str(theme)+\".h5\"\n",
    "    model.save(repo)\n",
    "    return r\n",
    "\n",
    "def DisplayAccuracy(r):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(r.history['accuracy'])\n",
    "    \n",
    "def predict_words(seed, no_words,model,tokenizer,maxLenInputSeq,theme):\n",
    "    for i in range(no_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=maxLenInputSeq-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=1)\n",
    "\n",
    "        new_word = ''\n",
    "\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if predicted == index:\n",
    "                new_word = word\n",
    "                break\n",
    "        seed += \" \" + new_word\n",
    "    print(seed)\n",
    "    filename = \"./outputs/\"+str(theme) + \".txt\"\n",
    "    with open(filename, 'w') as txtfile:\n",
    "        txtfile.write(seed) \n",
    "    \n",
    "    \n",
    "def Menu():\n",
    "    choice = ['depression','evil','funny','god','love','moon','mother','romance','war','wedding']\n",
    "    position = -1\n",
    "    while (position < 0 or position > 9):\n",
    "        try: \n",
    "            position = int(input(\"Choose 1 topic :0. depression, 1. evil, 2. funny, 3. god, 4. love, 5. moon, 6. mother, 7. romance, 8. war, 9. wedding \\n\"))\n",
    "        except: \n",
    "            print(\"Choose a number\")\n",
    "    return choice[position]\n",
    "        \n",
    "def main():\n",
    "    theme = Menu()\n",
    "    TextLine = ObtainTexts(theme)\n",
    "    TextLine = dataCleaning(TextLine)\n",
    "    vocab_size,tokenizer = tokenize(TextLine)\n",
    "    input_seq = sentToSeq(TextLine,tokenizer)\n",
    "    maxLenInputSeq = maxLenSequence(input_seq)\n",
    "    input_seq  = padAndArray(input_seq,maxLenInputSeq)\n",
    "    xs,labels = XAndLabel(input_seq)\n",
    "    ys = categorical(labels,vocab_size)\n",
    "    \n",
    "    repo = \"models/model_\"+str(theme)+\".h5\"\n",
    "    if not(exists(repo)):\n",
    "        r = textGeneratorModel(vocab_size,maxLenInputSeq,xs,ys,theme)\n",
    "        DisplayAccuracy(r)\n",
    "    \n",
    "    \n",
    "    model=load_model(repo) \n",
    "    seed_text = input('Write the begining of a sentence. (3 words)') #Begining of the sentence.\n",
    "    next_words = 300 #Number of word to generate\n",
    "    predict_words(seed_text, next_words,model,tokenizer,maxLenInputSeq,theme)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d61df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
