{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2f9e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose 1 topic :0. depression, 1. evil, 2. funny, 3. god, 4. love, 5. moon, 6. mother, 7. romance, 8. war, 9. wedding \n",
      "1\n",
      "You have chosen: evil \n",
      "\n",
      "Write the begining of a sentence. (3 words)I am evil\n",
      "Generated text: \n",
      " I am evil that i wish to protect out the evil in ten sleep crying requests to testify and lives in arkansas a foolish furrow dead for your honours invitation inside he life seems this children they caught called in my spirit dies my children dwelled for if you cannot neglect change my sin displays but hunger in this campus one of the street men a woman made you make you pay – ive omitted forever was in a screw and you the war and in my spirit dies is indeed but refs decision fazio drowned the forest men you met them you do not show respect her pages not to find if they die— told can never be returned eight dull satan my spirit displays and im wins as long if the diary of her mind in the heart of parents if him if the vision of a woman you walk alone of all at its soil my pardon past the lance when make someone the war born but the cornland side never never speak of good but one is in the street love beauty fear all known life peace peace peace but fate that love is magical appear she all worlds hold red or green life peace but peace peace peace peace peace but other must grow darkness someone to bad years satan fate he drew your sighs abode heaven abbadon around the countries on other bad bad bad bad bad caught pain and full of christ appeal to peer worlds true alarm always all worlds game must become not all if evil worlds your beauty only evil ridden he is weak i wasnt all right and you walk away you think wanted want him of the good who longs little good still town a good peace but fate that hes\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import exists\n",
    "import csv\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from keras.utils import np_utils\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Dropout, Bidirectional, GlobalMaxPooling1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#obtenir les lignes de chaque poèmes\n",
    "def ObtainTexts(theme):\n",
    "    TextLine = []\n",
    "    repo = \"PoemTopics/\"+ str(theme) + \"/\"\n",
    "    for filename in os.listdir(repo):\n",
    "        dir = str(repo)+str(filename)\n",
    "        file = open(dir, encoding=\"utf8\")\n",
    "        while(True):\n",
    "            line = file.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            else:\n",
    "                TextLine.append(line)\n",
    "    return TextLine\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r',', '', text)\n",
    "    text = re.sub(r'\\'', '',  text)\n",
    "    text = re.sub(r'\\\"', '', text)\n",
    "    text = re.sub(r'\\(', '', text)\n",
    "    text = re.sub(r'\\)', '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'“', '', text)\n",
    "    text = re.sub(r'”', '', text)\n",
    "    text = re.sub(r'’', '', text)\n",
    "    text = re.sub(r'\\.', '', text)\n",
    "    text = re.sub(r';', '', text)\n",
    "    text = re.sub(r':', '', text)\n",
    "    text = re.sub(r'\\-', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def dataCleaning(TextLine):\n",
    "    #enlever les \\n\n",
    "    for i in range(len(TextLine)):\n",
    "        TextLine[i] = TextLine[i].replace('\\n', '')\n",
    "        TextLine[i] = TextLine[i].lower()\n",
    "        TextLine[i] = clean_text(TextLine[i])\n",
    "    return TextLine\n",
    "\n",
    "def tokenize(TextLine):\n",
    "   # Instantiating the Tokenizer\n",
    "    max_vocab = 1000000\n",
    "    tokenizer = Tokenizer(num_words=max_vocab)\n",
    "    tokenizer.fit_on_texts(TextLine)   \n",
    "\n",
    "    # Getting the total number of words of the data.\n",
    "    word2idx = tokenizer.word_index\n",
    "    vocab_size = len(word2idx) + 1 \n",
    "    return vocab_size, tokenizer\n",
    "\n",
    "# We will turn the sentences to sequences line by line and create n_gram sequences [3,67,2,...]\n",
    "def sentToSeq(TextLine,tokenizer):\n",
    "    input_seq = []\n",
    "\n",
    "    for line in TextLine:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_seq = token_list[:i+1]\n",
    "            input_seq.append(n_gram_seq)\n",
    "    return input_seq\n",
    "\n",
    "# Getting the maximum length of sequence for padding purpose\n",
    "def maxLenSequence(input_seq):\n",
    "    return max(len(x) for x in input_seq)\n",
    "\n",
    "# Padding the sequences and converting them to array\n",
    "def padAndArray(input_seq,max_seq_length):\n",
    "    return np.array(pad_sequences(input_seq, maxlen=max_seq_length, padding='pre'))\n",
    "\n",
    "# Taking xs and labels to train the model. [0,0,0,...,x] x is a word that has been categorise\n",
    "def XAndLabel(input_seq):\n",
    "    xs = input_seq[:, :-1]        # xs contains every word in sentence except the last one because we are using this value to predict the y value\n",
    "    labels = input_seq[:, -1]     # labels contains only the last word of the sentence which will help in hot encoding the y value in next step\n",
    "    return xs,labels\n",
    "\n",
    "# one-hot encoding the labels according to the vocab size\n",
    "\n",
    "# The matrix is square matrix of the size of vocab_size. Each row will denote a label and it will have \n",
    "# a single +ve value(i.e 1) for that label and other values will be zero. \n",
    "def categorical(labels,vocab_size):\n",
    "    return to_categorical(labels, num_classes=vocab_size)\n",
    "\n",
    "\n",
    "def textGeneratorModel(vocab_size,max_seq_length,xs,ys,theme):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, input_length=max_seq_length-1))\n",
    "    model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(vocab_size/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    r = model.fit(xs,ys,epochs=125)\n",
    "    \n",
    "    repo = \"models/model_\"+str(theme)+\".h5\"\n",
    "    model.save(repo)\n",
    "    return r\n",
    "\n",
    "def DisplayAccuracy(r):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(r.history['accuracy'])\n",
    "    \n",
    "def predict_words(seed, no_words,model,tokenizer,maxLenInputSeq,theme):\n",
    "    for i in range(no_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=maxLenInputSeq-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=1)\n",
    "\n",
    "        new_word = ''\n",
    "\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if predicted == index:\n",
    "                new_word = word\n",
    "                break\n",
    "        seed += \" \" + new_word\n",
    "    print(\"Generated text: \\n\", seed)\n",
    "    filename = \"./outputs/\"+str(theme) + \".txt\"\n",
    "    with open(filename, 'w') as txtfile:\n",
    "        txtfile.write(seed) \n",
    "    \n",
    "    \n",
    "def Menu():\n",
    "    choice = ['depression','evil','funny','god','love','moon','mother','romance','war','wedding']\n",
    "    position = -1\n",
    "    while (position < 0 or position > 9):\n",
    "        try: \n",
    "            position = int(input(\"Choose 1 topic :0. depression, 1. evil, 2. funny, 3. god, 4. love, 5. moon, 6. mother, 7. romance, 8. war, 9. wedding \\n\"))\n",
    "        except: \n",
    "            print(\"Choose a number\")\n",
    "    print(\"You have chosen:\",str(choice[position]),\"\\n\")\n",
    "    return choice[position]\n",
    "        \n",
    "def main():\n",
    "    theme = Menu()\n",
    "    TextLine = ObtainTexts(theme)\n",
    "    TextLine = dataCleaning(TextLine)\n",
    "    vocab_size,tokenizer = tokenize(TextLine)\n",
    "    input_seq = sentToSeq(TextLine,tokenizer)\n",
    "    maxLenInputSeq = maxLenSequence(input_seq)\n",
    "    input_seq  = padAndArray(input_seq,maxLenInputSeq)\n",
    "    xs,labels = XAndLabel(input_seq)\n",
    "    ys = categorical(labels,vocab_size)\n",
    "    \n",
    "    repo = \"models/model_\"+str(theme)+\".h5\"\n",
    "    if not(exists(repo)):\n",
    "        r = textGeneratorModel(vocab_size,maxLenInputSeq,xs,ys,theme)\n",
    "        DisplayAccuracy(r)\n",
    "    \n",
    "    \n",
    "    model=load_model(repo) \n",
    "    seed_text = input('Write the begining of a sentence. (3 words)') #Begining of the sentence.\n",
    "    next_words = 300 #Number of word to generate\n",
    "    predict_words(seed_text, next_words,model,tokenizer,maxLenInputSeq,theme)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d61df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
